{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3455fe94-8b90-400c-ba6d-e8a2fa07cd25",
   "metadata": {},
   "source": [
    "# Fraglysis download notebook\n",
    "\n",
    "Allows to easily use the Fragalysis download API to get data for a target so that you can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea53c1-6867-477a-9f14-a6521cd39b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables that we are going to need. \n",
    "# Would these be accessible as environment variables?\n",
    "FRAGALYSIS_HOST = \"https://fragalysis.diamond.ac.uk\"\n",
    "FRAGALYSIS_TARGET = \"\"  # e.g. A71EV2A\n",
    "FRAGALYSIS_TAS = \"\"     # e.g. lb32627-66\n",
    "\n",
    "# user probably has to define this themselves.\n",
    "# 1. log in to Fragalysis (e.g. authenticate using CAS)\n",
    "# 2. Find you session token at https://fragalysis.diamond.ac.uk/api/token/ (or whatever Fragalysis URL you are using\n",
    "# 3. Copy the value of the sessionid and use it as part of this FRAGALYSIS_AUTH_TOKEN variable\n",
    "# NOTE: the session token only has a limited lifespan. Once it expires you need to repeat this process.\n",
    "FRAGALYSIS_AUTH_TOKEN = \"<paste-token-here>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a6ae9-3a0c-4e81-82cf-9edec57f5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the directory name of where your downloaded data will be extracted to.\n",
    "DATA_DIR = \"fragalysis-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4393e-d438-4188-bfd6-bee93d4bd99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this defines the download code that will be used later\n",
    "\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin, urlsplit\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "LOGIN_URL = \"/accounts/login/\"\n",
    "DOWNLOAD_URL = \"/api/download_structures/\"\n",
    "LANDING_PAGE_URL = '/viewer/react/landing/'\n",
    "\n",
    "\n",
    "# this needs to be kept more or less up to date\n",
    "USER_AGENT = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "\n",
    "\n",
    "def download(url, auth_token=None, payload=None):\n",
    "    print('Downloading from', url)\n",
    "    splits = urlsplit(url)\n",
    "    base_url = f'{splits.scheme}://{splits.netloc}'\n",
    "    download_api_url = urljoin(base_url, DOWNLOAD_URL)\n",
    "    landing_page_url = urljoin(url, LANDING_PAGE_URL)    \n",
    "\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update(\n",
    "            {\n",
    "                \"User-Agent\": USER_AGENT,\n",
    "                \"Referer\": landing_page_url,\n",
    "                \"Referrer-policy\": \"same-origin\",\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print('Getting Fragalysis landing page')\n",
    "        session.get(landing_page_url)  # sets csrftoken\n",
    "\n",
    "        # set manually if still missing\n",
    "        csrftoken = session.cookies.get('csrftoken', None)\n",
    "        if csrftoken:\n",
    "            session.headers.update(\n",
    "                {\n",
    "                    \"X-CSRFToken\": csrftoken,\n",
    "                    \"User-Agent\": USER_AGENT,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if auth_token:\n",
    "            session.cookies.update(\n",
    "                {\n",
    "                    \"sessionid\": auth_token,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # this will initiate zipfile creation process. Response is\n",
    "        # returned when the file is ready (this is not an async\n",
    "        # operation on the server, may take some time)\n",
    "        print('Initiating creation of download')\n",
    "        start_download_process_response = session.post(\n",
    "            download_api_url,\n",
    "            data=payload,\n",
    "        )\n",
    "        print(start_download_process_response)\n",
    "        # successful response contains the file_url, something like this\n",
    "        # {'file_url': '/code/media/downloads/c1b21660-b2ff-4e82-b928-e6f2d19582c7/A71EV2A.zip'}\n",
    "        \n",
    "\n",
    "        file_url_response = start_download_process_response.json()\n",
    "        print(start_download_process_response.json())\n",
    "        \n",
    "\n",
    "        if start_download_process_response.ok:\n",
    "            file_url = file_url_response['file_url']\n",
    "            print('Downloading file:', file_url)\n",
    "\n",
    "            local_filename = Path(file_url).name\n",
    "            with session.get(\n",
    "                    download_api_url,\n",
    "                    params=file_url_response,\n",
    "                    stream=True,\n",
    "            ) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(local_filename, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192): \n",
    "                        f.write(chunk)\n",
    "\n",
    "                print('Downloaded complete')\n",
    "                \n",
    "                \n",
    "                print('Unzipping ...')\n",
    "                with zipfile.ZipFile(local_filename, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(DATA_DIR)\n",
    "                    \n",
    "                print('Finished. Files can be found in', DATA_DIR)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ff949-44f2-4c81-9424-217aa2a79ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is probably what you're most interested in, the dict that\n",
    "# defines the download contents. Flipping the boolean switches to\n",
    "# True will include the file type. Avoid including map and other\n",
    "# huge files unless you really need them.\n",
    "\n",
    "# I don't quite understand the purpose of file_url in the initial\n",
    "# request, it has to be '', not False, for this to work. This is probably\n",
    "# a glitch in the serializer.\n",
    "\n",
    "# If you're interested in individual observations, add the\n",
    "# comma-separated list of shorcodes to 'proteins' key.\n",
    "\n",
    "\n",
    "# this defines what types of file you want to download\n",
    "payload = {\n",
    "    'target_name': FRAGALYSIS_TARGET,\n",
    "    'target_access_string': FRAGALYSIS_TAS,\n",
    "    'proteins': '',\n",
    "    'all_aligned_structures': True,\n",
    "    'pdb_info': True,\n",
    "    'cif_info': False,\n",
    "    'mtz_info': False,\n",
    "    'diff_file': False,\n",
    "    'event_file': False,\n",
    "    'sigmaa_file': False,\n",
    "    'map_info': False,\n",
    "    'single_sdf_file': False,\n",
    "    'metadata_info': False,\n",
    "    'static_link': False,\n",
    "    'file_url': '',\n",
    "    'trans_matrix_info': False,\n",
    "}\n",
    "\n",
    "# this runs the download\n",
    "download(\n",
    "    url=FRAGALYSIS_HOST,\n",
    "    auth_token=FRAGALYSIS_AUTH_TOKEN,\n",
    "    payload=payload,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f7e11-5197-44b2-894b-d54e9c39e967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
